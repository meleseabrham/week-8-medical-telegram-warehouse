# üè• Ethiopian Medical Data Warehouse

[![CI/CD Pipeline](https://github.com/meleseabrham/week-8-medical-telegram-warehouse/actions/workflows/main.yml/badge.svg)](https://github.com/meleseabrham/week-8-medical-telegram-warehouse/actions)

An end-to-end data engineering pipeline designed to archive, clean, and analyze medical business data from public Ethiopian Telegram channels. This project utilizes a sophisticated ELT stack including **Python**, **YOLOv8 AI**, **PostgreSQL**, **dbt**, **FastAPI**, and **Dagster**.

---

## üåü Core Features

- **üöÄ Scalable Incremental Scraping**: Smart scraping that only fetches new messages, optimizing resource usage.
- **üëÅÔ∏è YOLOv8 AI Enrichment**: Automatic object detection and image categorization (Promotions, Products, Lifestyle).
- **üèóÔ∏è Star Schema Warehouse**: Advanced dbt modeling for pharmaceutical and medical retail analytics.
- **‚ö° Analytical API**: High-performance FastAPI endpoints for real-time reporting.
- **üîÑ Full Orchestration**: Entire pipeline automated with Dagster (Daily schedules + Job monitoring).
- **üìä Intelligence Dashboard**: Interactive Jupyter notebook for visualizing business insights.

---

## üìÇ Project Structure

```text
‚îú‚îÄ‚îÄ api/                # FastAPI Analytical Layer
‚îú‚îÄ‚îÄ orchestration/      # Dagster Pipeline Definitions (Jobs, Ops, Schedules)
‚îú‚îÄ‚îÄ medical_warehouse/  # dbt Project (Transformation Logic)
‚îú‚îÄ‚îÄ notebooks/          # API Visualization Dashboards
‚îú‚îÄ‚îÄ src/                # Core Logic (Scraper, Loader, YOLO Detection)
‚îú‚îÄ‚îÄ data/               
‚îÇ   ‚îú‚îÄ‚îÄ raw/            # Scraped JSON & Images (Data Lake)
‚îÇ   ‚îî‚îÄ‚îÄ processed/      # YOLO Detection CSVs
‚îú‚îÄ‚îÄ tests/              # API and Pipeline Tests
‚îú‚îÄ‚îÄ logs/               # Execution audit trails
‚îî‚îÄ‚îÄ docker-compose.yml  # Database Infrastructure
```

---

## üõ†Ô∏è Installation & Setup

### 1. Prerequisites
- Python 3.10+
- Docker (for PostgreSQL)
- Telegram API Credentials ([my.telegram.org](https://my.telegram.org))

### 2. Configure Environment
Create a `.env` file in the root directory:
```env
# Telegram Auth
TG_API_ID=your_id
TG_API_HASH=your_hash

# Database (Default for Docker)
DB_HOST=localhost
DB_PORT=5433
DB_NAME=medical_db
DB_USER=sa
DB_PASS=123
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

---

## üèÉ How to Run

### **Option 1: Guided Orchestration (Recommended)**
The entire pipeline (Scrape -> Load -> YOLO -> dbt) is managed by Dagster.
```bash
python -m dagster dev -m orchestration
```
Then visit **[http://localhost:3000](http://localhost:3000)** to launch the `medical_pipeline_job`.

### **Option 2: Manual Execution**
If you prefer running individual components:
1. **Scrape Data**: `python src/scraper.py`
2. **Load to SQL**: `python src/load_data.py`
3. **Run AI Detection**: `python src/yolo_detect.py`
4. **dbt Transform**: `cd medical_warehouse && dbt run`
5. **Start API**: `uvicorn api.main:app --reload`

---

## üìà Analytical API Endpoints
The API serves business insights at `http://localhost:8000/docs`:
- `GET /api/reports/top-products`: Most frequent medical keywords.
- `GET /api/reports/visual-content`: Engagement stats by image category.
- `GET /api/channels/{name}/activity`: Channel-specific performance metrics.
- `GET /api/search/messages`: Full-text search across all collected data.

---

## ‚úÖ Quality & Compliance
- **CI/CD**: Fully passing GitHub Actions on `task-4` and `task-5`.
- **Testing**: Includes `pytest` for API and 15+ dbt tests for data integrity.
- **Scalability**: Implemented state tracking to prevent duplicate processing.

---

## üìù License
MIT License. Developed for Advanced Data Engineering Research.
